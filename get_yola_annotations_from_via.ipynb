{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cook_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_prc = 10\n",
    "create_empty = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/path/to/images'\n",
    "ds_name = 'my_dataset'\n",
    "prep_dirs(source_dir, ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert via annotate for 00_pack: 100%|██████████| 800/800 [00:00<00:00, 7449.57it/s]\n",
      "convert via annotate for 01_pack: 100%|██████████| 800/800 [00:01<00:00, 601.65it/s]\n",
      "convert via annotate for 02_pack: 100%|██████████| 800/800 [00:01<00:00, 791.42it/s] \n",
      "convert via annotate for 03_pack: 100%|██████████| 800/800 [00:01<00:00, 721.37it/s]\n",
      "convert via annotate for 04_pack: 100%|██████████| 650/650 [00:00<00:00, 676.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#fill train data\n",
    "train_img_path = os.path.join(source_dir, ds_name, 'images', 'train')\n",
    "train_lab_path = os.path.join(source_dir, ds_name, 'labels', 'train')\n",
    "\n",
    "for path in [d for d in sorted(os.listdir(source_dir)) if d.endswith('_val.json')]:\n",
    "    path_json = os.path.join(source_dir, path)\n",
    "    info = viaLabels(path_json)\n",
    "    path_images = os.path.join(source_dir, os.path.dirname(path), info[0])\n",
    "    out = via2yola(path_json, path_images, info[1])\n",
    "    \n",
    "    for txt in out:\n",
    "        if create_empty or len(out[txt]) > 0:   \n",
    "            img_file = os.path.join(path_images, txt[:-4] + '.jpg')\n",
    "            if os.path.exists(img_file):\n",
    "                shutil.copy(img_file, os.path.join(train_img_path, txt[:-4] + '.jpg'))\n",
    "                with open(os.path.join(train_lab_path, txt), 'w') as f:\n",
    "                    f.write('\\n'.join(out[txt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds_path = os.path.join(source_dir, ds_name)\n",
    "with open(ds_path + '.yaml', 'w') as f:\n",
    "    f.write('train: {}\\n'.format(ds_path + os.sep))\n",
    "    f.write('val: {}\\n\\n'.format(ds_path + os.sep))\n",
    "    f.write('nc: {}\\n\\n'.format(len(info[1].keys())))\n",
    "    f.write('names: {}\\n'.format(list(info[1].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0_side': '0',\n",
       " '100_bills': '1',\n",
       " '200_bills': '2',\n",
       " '500_bills': '3',\n",
       " '1000_bills': '4',\n",
       " '2000_bills': '5',\n",
       " '5000_bills': '6',\n",
       " '0_box_closed': '7',\n",
       " '0_box': '8',\n",
       " '100_box_brown': '9',\n",
       " '200_box_green': '10',\n",
       " '500_box_violet': '11',\n",
       " '1000_box_turquoise': '12',\n",
       " '2000_box_blue': '13',\n",
       " '5000_box_orange': '14'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print \"1\" if need create val with 10% of train_set: 1\n"
     ]
    }
   ],
   "source": [
    "#fill val data\n",
    "val_img_path = os.path.join(source_dir, ds_name, 'images', 'val')\n",
    "val_lab_path = os.path.join(source_dir, ds_name, 'labels', 'val')\n",
    "\n",
    "if input('print \"1\" if need create val with {}% of train_set: '.format(val_prc)) == '1':\n",
    "    train_set = os.listdir(train_img_path)\n",
    "    random.shuffle(train_set)\n",
    "\n",
    "    val_cnt = len(train_set) // val_prc\n",
    "    val_set = train_set[:val_cnt]\n",
    "\n",
    "    for vs in val_set:\n",
    "        shutil.move(os.path.join(train_img_path, vs), os.path.join(val_img_path, vs))\n",
    "        shutil.move(os.path.join(train_lab_path, vs[:-4] + '.txt'), os.path.join(val_lab_path, vs[:-4] + '.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_p36",
   "language": "python",
   "name": "torch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
